{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Physics-Informed RNN model for PINN training with state encoder\n",
    "output-file: pirnn.html\n",
    "title: PIRNN\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pinn.pirnn\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tsfast.prediction.fransys import Diag_RNN, FranSysLearner\n",
    "from tsfast.models.rnn import RNN\n",
    "from tsfast.models.layers import SeqLinear\n",
    "from tsfast.learner.callbacks import CB_TruncateSequence\n",
    "from tsfast.learner.losses import SkipNLoss\n",
    "from fastai.basics import *\n",
    "from fastcore.basics import store_attr\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIRNN Model\n",
    "\n",
    "Physics-Informed RNN (PIRNN) extends the FranSys architecture with a **StateEncoder** for single-state initialization. This enables training with collocation points that don't have full sequence observations.\n",
    "\n",
    "**Architecture:**\n",
    "- **SequenceEncoder** (Diagnosis RNN): Processes observation sequences → hidden state (from FranSys)\n",
    "- **StateEncoder** (NEW): Maps single physical state → hidden state (for collocation points)\n",
    "- **Prognosis RNN**: Predicts future from hidden state (from FranSys)\n",
    "- **Final Layer**: Hidden state → outputs (from FranSys)\n",
    "\n",
    "**Training modes:**\n",
    "1. Real sequences → SequenceEncoder\n",
    "2. Random physical states → StateEncoder  \n",
    "3. Random hidden states → direct initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PIRNN(nn.Module):\n",
    "    '''Physics-Informed RNN with dual encoders: Sequence and State'''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_u:int, # Number of inputs\n",
    "                 n_y:int, # Number of outputs\n",
    "                 init_sz:int, # Initialization sequence length\n",
    "                 n_x:int = 0, # Number of extra states\n",
    "                 hidden_size:int = 100, # Hidden state size\n",
    "                 rnn_layer:int = 1, # Number of RNN layers\n",
    "                 state_encoder_hidden:int = 64, # Hidden size for state encoder MLP\n",
    "                 linear_layer:int = 1, # Linear layers in diagnosis RNN\n",
    "                 final_layer:int = 0, # Final layer complexity\n",
    "                 init_diag_only:bool = False, # Limit diagnosis to init_sz\n",
    "                 default_encoder_mode:str = 'sequence', # Default encoder mode\n",
    "                 **kwargs\n",
    "                ):\n",
    "        '''Initialize PIRNN with both sequence and state encoders'''\n",
    "        super().__init__()\n",
    "        store_attr('n_u,n_y,n_x,init_sz,init_diag_only,hidden_size,rnn_layer,default_encoder_mode')\n",
    "        \n",
    "        # Instantiate FranSys components\n",
    "        self.rnn_diagnosis = Diag_RNN(\n",
    "            n_u+n_x+n_y, hidden_size, \n",
    "            hidden_size=hidden_size,\n",
    "            output_layer=rnn_layer,\n",
    "            rnn_layer=rnn_layer,\n",
    "            linear_layer=linear_layer,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        rnn_kwargs = dict(hidden_size=hidden_size, num_layers=rnn_layer, ret_full_hidden=True)\n",
    "        rnn_kwargs = dict(rnn_kwargs, **kwargs)\n",
    "        self.rnn_prognosis = RNN(n_u, **rnn_kwargs)\n",
    "        \n",
    "        self.final = SeqLinear(hidden_size, n_y, hidden_layer=final_layer)\n",
    "        \n",
    "        # State encoder: physical state -> hidden state\n",
    "        self.state_encoder = nn.Sequential(\n",
    "            nn.Linear(n_y, state_encoder_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(state_encoder_hidden, hidden_size * rnn_layer)\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x:torch.Tensor, # Input tensor\n",
    "        init_state:list = None, # Initial hidden state (optional)\n",
    "        encoder_mode:str = 'default' # 'none', 'sequence', or 'state'\n",
    "    ) -> torch.Tensor: # Output predictions\n",
    "        '''Forward pass with encoder mode auto-detection or explicit selection'''\n",
    "\n",
    "        u = x[:,:,:self.n_u]\n",
    "        x_init = x[:,:self.init_sz,:self.n_u+self.n_x+self.n_y]\n",
    "        if encoder_mode == 'default':\n",
    "            encoder_mode = self.default_encoder_mode\n",
    "        \n",
    "        # Detect encoder mode based on input shape\n",
    "        if encoder_mode == 'none':\n",
    "            return self._forward_predictor(u, init_state)\n",
    "        elif encoder_mode == 'sequence':\n",
    "            return self._forward_sequence_encoder(u[:,self.init_sz:], x_init, init_state)\n",
    "        elif encoder_mode == 'state':\n",
    "            return self._forward_state_encoder(u[:,self.init_sz:], x_init, init_state)\n",
    "        else:\n",
    "            raise ValueError(f\"encoder_mode must be 'none', 'sequence', or 'state', got {encoder_mode}\")\n",
    "    \n",
    "    def _forward_sequence_encoder(\n",
    "        self,\n",
    "        u:torch.Tensor, # Full input [batch, seq, n_u+n_x+n_y]\n",
    "        x_init:torch.Tensor, # Initial state [batch, seq, n_x+n_y]\n",
    "        init_state:list = None # Initial hidden state (optional)\n",
    "    ) -> torch.Tensor: # Output predictions\n",
    "        '''Forward using sequence encoder (diagnosis RNN)'''\n",
    "        out_init,_ = self.rnn_diagnosis(x_init)\n",
    "        if init_state is None:\n",
    "            init_state = self.rnn_diagnosis.output_to_hidden(out_init, -1)\n",
    "        out_prog,self.new_hidden = self.rnn_prognosis(u, init_state)\n",
    "        out_prog = torch.cat([out_init, out_prog], 2)\n",
    "\n",
    "        result = self.final(out_prog[-1])\n",
    "        return result\n",
    "    \n",
    "    def _forward_state_encoder(\n",
    "        self,\n",
    "        u:torch.Tensor, # Prognosis input [batch, seq, n_u]\n",
    "        x_init:torch.Tensor, # Prognosis input [batch, seq, n_x + n_y]\n",
    "        init_state, \n",
    "    ) -> torch.Tensor: # Output predictions\n",
    "        if init_state is None: # If init_state is not provided, use last initialization step\n",
    "            init_state = x_init[:,-1,-self.n_y:]\n",
    "        init_state = self.encode_single_state(init_state)\n",
    "        pred = self._forward_predictor(u, init_state)\n",
    "        if self.training:\n",
    "            init_state_output = self.final(init_state[-1].squeeze(0).unsqueeze(1))\n",
    "            init_state_output = init_state_output.repeat(1, self.init_sz, 1)\n",
    "            return torch.cat([init_state_output, pred], 1)\n",
    "        else:\n",
    "            return F.pad(pred, (0, 0, self.init_sz, 0)) # Pad with zeros to match full sequence length\n",
    "\n",
    "\n",
    "    def _forward_predictor(\n",
    "        self,\n",
    "        u:torch.Tensor, # Input tensor\n",
    "        init_state:list # Initial hidden state\n",
    "    ) -> torch.Tensor: # Output predictions\n",
    "        '''Forward using predictor RNN'''\n",
    "        out_prog,_ = self.rnn_prognosis(u, init_state)\n",
    "        return self.final(out_prog[-1])\n",
    "    \n",
    "    def encode_single_state(\n",
    "        self,\n",
    "        physical_state:torch.Tensor # Physical state [batch, n_y]\n",
    "    ) -> list: # Hidden state compatible with RNN [rnn_layer, batch, hidden_size]\n",
    "        '''Convert single physical state to RNN-compatible hidden state'''\n",
    "        batch_size = physical_state.shape[0]\n",
    "        \n",
    "        # Encode: [batch, n_y] -> [batch, hidden_size * rnn_layer]\n",
    "        h_flat = self.state_encoder(physical_state)\n",
    "        \n",
    "        # Reshape to RNN format: [rnn_layer, batch, hidden_size]\n",
    "        h = h_flat.view(batch_size, self.rnn_layer, self.hidden_size)\n",
    "        h = h.transpose(0, 1).contiguous()  # [rnn_layer, batch, hidden_size]\n",
    "        \n",
    "        # Convert to list format expected by Diag_RNN.output_to_hidden\n",
    "        return [h[i:i+1] for i in range(self.rnn_layer)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage\n",
    "\n",
    "Basic PIRNN model creation and state encoding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence encoder output: torch.Size([4, 20, 2])\n",
      "State encoder output: torch.Size([4, 20, 2])\n"
     ]
    }
   ],
   "source": [
    "model = PIRNN(n_u=1, n_y=2, init_sz=10, hidden_size=50, rnn_layer=2)\n",
    "\n",
    "# Test 1: Sequence encoder (auto-detected)\n",
    "x_full = torch.randn(4, 20, 3)  # [batch, seq, n_u+n_y]\n",
    "output_seq = model(x_full, encoder_mode='sequence')\n",
    "print(f\"Sequence encoder output: {output_seq.shape}\")\n",
    "\n",
    "# Test 2: State encoder with explicit mode\n",
    "x_input = torch.randn(4, 20, 1)  # [batch, seq, n_u] \n",
    "physical_state = torch.randn(4, 2)\n",
    "output_state = model(x_input, init_state=physical_state, encoder_mode='state')\n",
    "print(f\"State encoder output: {output_state.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIRNN Learner\n",
    "\n",
    "Convenience function to create a PIRNN learner with appropriate settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(PIRNN, keep=True)\n",
    "def PIRNNLearner(\n",
    "    dls, # DataLoaders\n",
    "    init_sz:int, # Initialization sequence length\n",
    "    attach_output:bool = False, # Whether to attach output to input\n",
    "    loss_func = nn.L1Loss(), # Loss function\n",
    "    metrics = None, # Metrics\n",
    "    opt_func = Adam, # Optimizer\n",
    "    lr:float = 3e-3, # Learning rate\n",
    "    cbs = None, # Additional callbacks\n",
    "    **kwargs # Additional arguments for PIRNN\n",
    "):\n",
    "    '''Create PIRNN learner with appropriate configuration'''\n",
    "    from tsfast.prediction.core import PredictionCallback\n",
    "    from tsfast.learner.losses import fun_rmse\n",
    "    \n",
    "    cbs = [] if cbs is None else list(cbs)\n",
    "    metrics = [fun_rmse] if metrics is None else list(metrics) if is_iter(metrics) else [metrics]\n",
    "    \n",
    "    _batch = dls.one_batch()\n",
    "    inp = _batch[0].shape[-1]\n",
    "    out = _batch[1].shape[-1]\n",
    "\n",
    "    if attach_output:\n",
    "        model = PIRNN(inp, out, init_sz, **kwargs)\n",
    "\n",
    "        # Add PredictionCallback if not present\n",
    "        if not any(isinstance(cb, PredictionCallback) for cb in cbs):\n",
    "            pred_callback = PredictionCallback(0)\n",
    "            pred_callback.init_normalize(_batch)\n",
    "            cbs.append(pred_callback)\n",
    "    else:\n",
    "        model = PIRNN(inp-out, out, init_sz, **kwargs)\n",
    "\n",
    "    # For long sequences, add truncation callback\n",
    "    seq_len = _batch[0].shape[1]\n",
    "    LENGTH_THRESHOLD = 300\n",
    "    if seq_len > init_sz + LENGTH_THRESHOLD:\n",
    "        if not any(isinstance(cb, CB_TruncateSequence) for cb in cbs):\n",
    "            INITIAL_SEQ_LEN = 100\n",
    "            cbs.append(CB_TruncateSequence(init_sz + INITIAL_SEQ_LEN))\n",
    "  \n",
    "    # Skip initial timesteps in loss/metrics\n",
    "    skip = partial(SkipNLoss, n_skip=init_sz)\n",
    "    metrics = [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(dls, model, loss_func=loss_func, metrics=metrics, cbs=cbs, opt_func=opt_func, lr=lr)\n",
    "    return lrn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfast.pinn.core import diff1_forward\n",
    "from tsfast.datasets.core import create_dls\n",
    "from tsfast.learner.losses import zero_loss, fun_rmse\n",
    "from tsfast.pinn.core import PhysicsLossCallback, CollocationPointsCB, generate_excitation_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../../test_data/pinn\")\n",
    "dls = create_dls(\n",
    "    u=['u'],  # Input signal names\n",
    "    y=['x','v'],  # Output signal names\n",
    "    dataset=path,\n",
    "    win_sz=300,  # Full sequence length\n",
    "    stp_sz=1,  # Non-overlapping windows\n",
    "    valid_stp_sz=1,\n",
    "    bs=16,\n",
    "    n_batches_train=50\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical parameters (must match dataset generation)\n",
    "MASS = 1.0\n",
    "SPRING_CONSTANT = 1.0\n",
    "DAMPING_COEFFICIENT = 0.1\n",
    "DT = 0.01\n",
    "\n",
    "init_sz = 10\n",
    "def spring_damper_physics(u, y_pred, y_ref):\n",
    "    '''Physics loss for spring-damper: ma + cv + kx = u'''\n",
    "    x = y_pred[:, :, 0]\n",
    "    v = y_pred[:, :, 1]\n",
    "    u_force = u[:, :, 0]\n",
    "    \n",
    "    a = diff1_forward(v, DT)\n",
    "    dx_dt = diff1_forward(x, DT)\n",
    "    \n",
    "    physics_start = 0\n",
    "    physics_loss = {\n",
    "        'physics': ((MASS * a[:,physics_start:] + DAMPING_COEFFICIENT * v[:,physics_start:] + SPRING_CONSTANT * x[:,physics_start:] - u_force[:,physics_start:]) ** 2).mean(),\n",
    "        'derivative': ((v[:,physics_start:] - dx_dt[:,physics_start:]) ** 2).mean(),\n",
    "    }\n",
    "    \n",
    "    # Add initial condition loss only when y_ref is provided\n",
    "    if y_ref is not None:\n",
    "        x_ref = y_ref[:, :, 0]\n",
    "        v_ref = y_ref[:, :, 1]\n",
    "        physics_loss['initial'] = ((x[:, :init_sz]-x_ref[:, :init_sz]) ** 2).mean() + ((v[:, :init_sz]-v_ref[:, :init_sz]) ** 2).mean()\n",
    "    \n",
    "    return physics_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.841751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213517</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = PIRNNLearner(\n",
    "    dls,\n",
    "    init_sz=init_sz,\n",
    "    attach_output=True,\n",
    "    rnn_type='gru',\n",
    "    rnn_layer=1,\n",
    "    hidden_size=20,\n",
    "    state_encoder_hidden=32,\n",
    "    loss_func=zero_loss,\n",
    "    metrics=[fun_rmse]\n",
    ")\n",
    "\n",
    "# 1. Physics loss on real data (uses SequenceEncoder)\n",
    "learn.add_cb(PhysicsLossCallback(\n",
    "    norm_input=dls.train.after_batch[0],\n",
    "    physics_loss_func=spring_damper_physics,\n",
    "    weight=1.0,\n",
    "    loss_weights={'physics': 1.0, 'derivative': 1.0, 'initial': 10.0},\n",
    "    n_inputs=1\n",
    "))\n",
    "\n",
    "# 2. Collocation with StateEncoder (random physical states → hidden states)\n",
    "learn.add_cb(CollocationPointsCB(\n",
    "    norm_input=dls.train.after_batch[0],\n",
    "    generate_pinn_input=lambda bs, sl, dev: generate_excitation_signals(\n",
    "        bs, sl, n_inputs=1, dt=DT, device=dev,\n",
    "        amplitude_range=(0.5, 2.0),\n",
    "        frequency_range=(0.1, 3.0)\n",
    "    ),\n",
    "    physics_loss_func=spring_damper_physics,\n",
    "    weight=0.5,\n",
    "    loss_weights={'physics': 1.0, 'derivative': 1.0, 'initial': 5.0},\n",
    "    init_mode='state_encoder',\n",
    "    output_ranges=[(-1.0, 1.0), (-2.0, 2.0)]\n",
    "))\n",
    "\n",
    "learn.fit_flat_cos(1, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import nbdev; nbdev.nbdev_export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
