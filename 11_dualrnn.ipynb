{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dualrnn\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual RNN Models\n",
    "> Pytorch Models for Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.models.core import *\n",
    "from seqdata.learner import *\n",
    "from seqdata.dataloaders import *\n",
    "from fastai.basics import *\n",
    "from fastai.callback.progress import *\n",
    "from fastai.callback.schedule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sz = 100\n",
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[0,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[-1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=20000+1,stp_sz=2000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "dl_kwargs=[{'sub_seq_len':1000}]*2\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'),bs=32,dl_type=TbpttDl,dl_kwargs=dl_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "db.show_batch(max_n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProDiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProDiagTrainer(Callback):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n",
    "    def __init__(self, alpha=1e6,beta=1,p_own_state=0):\n",
    "        store_attr('alpha,beta,p_own_state')\n",
    "        self.main_init_prop = None\n",
    "\n",
    "    def _has_main_init(self):\n",
    "        return hasattr(self.learn.model,'main_init_prop')\n",
    "\n",
    "    def before_fit(self):\n",
    "        if self._has_main_init():\n",
    "            self.main_init_prop=self.learn.model.main_init_prop\n",
    "\n",
    "    def before_batch(self):\n",
    "        if not self.training or self.p_own_state == 0: return\n",
    "        main_init_prop = random.random()< self.p_own_state\n",
    "        self.learn.model.main_init_prop = main_init_prop\n",
    "\n",
    "    def after_pred(self):\n",
    "        p,self.pred_diag,self.est_hidden,self.pred_hidden=self.pred\n",
    "        self.learn.pred = p\n",
    "\n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "        self.learn.loss = self.learn.loss+self.beta*self.learn.loss_func(self.pred_diag,*self.yb)\n",
    "\n",
    "        hidden_loss = ((self.est_hidden-self.pred_hidden)/\n",
    "                       (self.est_hidden.norm()+self.pred_hidden.norm())).pow(2).mean()\n",
    "        self.learn.loss = self.learn.loss+self.alpha * hidden_loss\n",
    "\n",
    "    def before_validate(self):\n",
    "        '''Set Dual RNN to reuse the prediction state after each mini batch on validation'''\n",
    "        if self._has_main_init():\n",
    "            self.learn.model.main_init_prop = True\n",
    "\n",
    "    def after_validate(self):\n",
    "        '''Reset Dual RNN to training state propagation behaviour'''\n",
    "        if self._has_main_init():\n",
    "            self.learn.model.main_init_prop=self.main_init_prop\n",
    "\n",
    "\n",
    "    def after_fit(self):\n",
    "        reset_model_state(self.learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualRNN(nn.Module):\n",
    "    \n",
    "    @delegates(RNN, keep=True)\n",
    "    def __init__(self,main_input_size,co_input_size,output_size,init_sz=100,hidden_size=100,\n",
    "                 rnn_layer=1,linear_layer = 1,main_init_est = True,main_init_prop = True,**kwargs):\n",
    "        super().__init__()\n",
    "        store_attr('main_input_size,co_input_size,main_init_est,main_init_prop,init_sz')\n",
    "        \n",
    "        rnn_kwargs = dict(hidden_size=hidden_size,num_layers=rnn_layer,stateful=True,ret_full_hidden=True)\n",
    "        rnn_kwargs = dict(rnn_kwargs, **kwargs)\n",
    "        \n",
    "        self.co_rnn = RNN(co_input_size,**rnn_kwargs) \n",
    "        self.main_rnn = RNN(main_input_size,**rnn_kwargs) \n",
    "\n",
    "#         self.co_estimator = SeqLinear(hidden_size,output_size,hidden_layer=linear_layer)\n",
    "        self.main_estimator = SeqLinear(hidden_size,output_size,hidden_layer=linear_layer)\n",
    "\n",
    "    def forward(self, x,init_state = None):\n",
    "        bs = x.shape[0]\n",
    "        if init_state is None:\n",
    "            init_state = self.main_rnn._get_hidden(bs) if self.main_init_prop else self.co_rnn._get_hidden(bs)\n",
    "        \n",
    "        \n",
    "        x_co = x[...,:self.co_input_size]\n",
    "        x_main = x[...,:self.main_input_size]\n",
    "            \n",
    "        #RNN Layer \n",
    "        if init_state is None:\n",
    "#             import pdb; pdb.set_trace()\n",
    "            if self.main_init_est:\n",
    "                out_init,h_init = self.main_rnn(x_main[:,:self.init_sz])\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "            else:\n",
    "                out_init,h_init = self.co_rnn(x_co[:,:self.init_sz])\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "        else:  \n",
    "            out_co,_ = self.co_rnn(x_co,init_state)         \n",
    "            out_main,_ = self.main_rnn(x_main,init_state)\n",
    "            \n",
    "            \n",
    "#         import pdb; pdb.set_trace()\n",
    "            \n",
    "        #Shared Linear Layer\n",
    "        est_co = self.main_estimator(out_co[-1])\n",
    "        est_main = self.main_estimator(out_main[-1])\n",
    "\n",
    "#         import pdb; pdb.set_trace()   \n",
    "        return est_main,est_co, out_co,out_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f99177bd150>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DualRNN(1,2,1,init_sz=500,linear_layer=2,rnn_layer=1,hidden_size=100,main_init_est=False,main_init_prop=False)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss(),cbs=ProDiagTrainer(),opt_func=ranger)\n",
    "lrn.add_cb(TbpttResetCB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.333662</td>\n",
       "      <td>0.172134</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualCRNN(nn.Module):\n",
    "    \n",
    "    @delegates(RNN, keep=True)\n",
    "    def __init__(self,main_input_size,co_input_size,output_size,init_sz=100,tcn_hidden_size=100,tcn_layer=8,rnn_hidden_size=100,\n",
    "                 rnn_layer=1,linear_layer = 1,main_init_est = True,main_init_prop = True,**kwargs):\n",
    "        super().__init__()\n",
    "        store_attr('main_input_size,co_input_size,main_init_est,main_init_prop,init_sz')\n",
    "        \n",
    "        rnn_kwargs = dict(hidden_size=rnn_hidden_size,num_layers=rnn_layer,stateful=True,ret_full_hidden=True)\n",
    "        rnn_kwargs = dict(rnn_kwargs, **kwargs)\n",
    "        \n",
    "        self.co_tcn = TCN(co_input_size,rnn_hidden_size,tcn_layer,tcn_hidden_size,stateful=True) \n",
    "        self.main_tcn = TCN(main_input_size,rnn_hidden_size,tcn_layer,tcn_hidden_size,stateful=True)\n",
    "        \n",
    "        self.co_rnn = RNN(rnn_hidden_size,**rnn_kwargs) \n",
    "        self.main_rnn = RNN(rnn_hidden_size,**rnn_kwargs) \n",
    "\n",
    "#         self.co_estimator = SeqLinear(rnn_hidden_size,output_size,hidden_layer=linear_layer)\n",
    "        self.main_estimator = SeqLinear(rnn_hidden_size,output_size,hidden_layer=linear_layer)\n",
    "\n",
    "    def forward(self, x,init_state = None):\n",
    "        bs = x.shape[0]\n",
    "        if init_state is None:\n",
    "            init_state = self.main_rnn._get_hidden(bs) if self.main_init_prop else self.co_rnn._get_hidden(bs)\n",
    "        \n",
    "        \n",
    "        x_co = x[...,:self.co_input_size]\n",
    "        x_main = x[...,:self.main_input_size]\n",
    "        \n",
    "        #TCN Layer\n",
    "        x_co = self.co_tcn(x_co)\n",
    "        x_main = self.main_tcn(x_main)\n",
    "        \n",
    "            \n",
    "        #RNN Layer \n",
    "        if init_state is None:\n",
    "#             import pdb; pdb.set_trace()\n",
    "            if self.main_init_est:\n",
    "                out_init,h_init = self.main_rnn(x_main[:,:self.init_sz])\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "            else:\n",
    "                out_init,h_init = self.co_rnn(x_co[:,:self.init_sz])\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "        else:  \n",
    "            out_co,_ = self.co_rnn(x_co,init_state)         \n",
    "            out_main,_ = self.main_rnn(x_main,init_state)\n",
    "            \n",
    "            \n",
    "#         import pdb; pdb.set_trace()\n",
    "            \n",
    "        #Shared Linear Layer\n",
    "        est_co = self.main_estimator(out_co[-1])\n",
    "        est_main = self.main_estimator(out_main[-1])\n",
    "\n",
    "#         import pdb; pdb.set_trace()   \n",
    "        return est_main,est_co, out_co,out_main\n",
    "\n",
    "    def get_main_crnn(self):\n",
    "        crnn_model = CRNN(1,1)\n",
    "        crnn_model.cnn = self.main_tcn\n",
    "        \n",
    "        simple_rnn_model = SimpleRNN(1,1)\n",
    "        simple_rnn_model.rnn = self.main_rnn\n",
    "        simple_rnn_model.final = self.main_estimator\n",
    "        crnn_model.rnn = simple_rnn_model\n",
    "        return crnn_model\n",
    "    \n",
    "    \n",
    "    def get_co_crnn(self):\n",
    "        crnn_model = CRNN(1,1)\n",
    "        crnn_model.cnn = self.co_tcn\n",
    "        \n",
    "        simple_rnn_model = SimpleRNN(1,1)\n",
    "        simple_rnn_model.rnn = self.co_rnn\n",
    "        simple_rnn_model.final = self.main_estimator\n",
    "        crnn_model.rnn = simple_rnn_model\n",
    "        return crnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f9945753910>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DualCRNN(1,2,1,init_sz=500,main_init_est=False,main_init_prop=False)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss(),cbs=ProDiagTrainer(),opt_func=ranger)\n",
    "lrn.add_cb(TbpttResetCB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): TCN(\n",
       "    (conv_layers): Sequential(\n",
       "      (0): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(1, 100, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "        (residual): Conv1d(1, 100, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "      (2): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "      (3): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "      (4): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "      (5): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "      (6): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "      (7): TCN_Block(\n",
       "        (layers): Sequential(\n",
       "          (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (rnn): SimpleRNN(\n",
       "    (rnn): RNN(\n",
       "      (rnns): ModuleList(\n",
       "        (0): GRU(100, 100, batch_first=True)\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "    (final): SeqLinear(\n",
       "      (lin): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "        (1): Conv1d(100, 1, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_main_crnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btch = 6\n",
    "# plt.figure()\n",
    "# plt.plot(lrn.y.cpu()[btch,:,0])\n",
    "# plt.plot(lrn.pred.cpu()[btch,:,0])\n",
    "# plt.figure()\n",
    "# plt.plot(lrn.y.cpu()[btch,:,0])\n",
    "# plt.plot(lrn.pred.cpu()[btch,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 01a_IndRNN.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_dataloaders.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_HPOpt.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
