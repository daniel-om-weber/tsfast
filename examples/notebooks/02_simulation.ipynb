{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e6ba2f",
   "metadata": {},
   "source": [
    "# Example 02: Simulation -- Training on Multiple Datasets\n",
    "\n",
    "Simulation is the most common mode in system identification: the model predicts\n",
    "output y(t) from input u(t) alone, with no access to past measured outputs. This\n",
    "example trains simulation models on benchmark datasets and introduces\n",
    "`InferenceWrapper` for numpy-based inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83fcaf",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook builds on concepts from Examples 00 and 01. Make sure you are\n",
    "familiar with creating DataLoaders and training a basic model before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3996c11",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27467e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tsfast.datasets.benchmark import create_dls_silverbox, create_dls_wh\n",
    "from tsfast.models.rnn import RNNLearner\n",
    "from tsfast.inference import InferenceWrapper\n",
    "from tsfast.learner.losses import fun_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f6425",
   "metadata": {},
   "source": [
    "## What is Simulation?\n",
    "\n",
    "In simulation mode, the model sees **only the input signal** u(t) and must predict\n",
    "the output y(t). The model has no access to measured outputs -- it must simulate\n",
    "the system's behavior purely from the input.\n",
    "\n",
    "This is the simplest and most common mode for system identification. Think of it\n",
    "as a black-box model that takes a control signal and predicts what the system will\n",
    "do, without ever \"peeking\" at the real measurements during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fc8a5",
   "metadata": {},
   "source": [
    "## Load the Silverbox Dataset\n",
    "\n",
    "The Silverbox is a standard benchmark in system identification. It is an\n",
    "electronic circuit that mimics a nonlinear mass-spring-damper system.\n",
    "\n",
    "- `bs=16`: batch size of 16 windows per training step\n",
    "- `win_sz=500`: each training window is 500 timesteps long\n",
    "- `stp_sz=10`: consecutive windows are offset by 10 timesteps (overlapping windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ff6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls_silverbox(bs=16, win_sz=500, stp_sz=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ad3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3a2c4",
   "metadata": {},
   "source": [
    "## Train an LSTM with n_skip\n",
    "\n",
    "RNNs start with a zero hidden state, so the first N predictions are unreliable\n",
    "because the network hasn't \"warmed up\" yet. The `n_skip` parameter excludes the\n",
    "first N timesteps from the loss computation, so the model isn't penalized for the\n",
    "transient warmup period.\n",
    "\n",
    "Key parameters:\n",
    "\n",
    "- `rnn_type='lstm'`: use an LSTM cell (alternatives: `'gru'`, `'rnn'`)\n",
    "- `n_skip=50`: exclude the first 50 timesteps from the loss\n",
    "- `hidden_size=40`: 40 hidden units in the LSTM layer\n",
    "- `metrics=[fun_rmse]`: track root mean squared error during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = RNNLearner(dls, rnn_type='lstm', n_skip=50, hidden_size=40, metrics=[fun_rmse])\n",
    "lrn.fit_flat_cos(n_epoch=10, lr=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32837cc0",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "`show_results` overlays the model's predictions against the true output on\n",
    "validation windows. The model has never seen these windows during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn.show_results(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284a5ee",
   "metadata": {},
   "source": [
    "## Evaluating on Different Data Splits\n",
    "\n",
    "tsfast DataLoaders can hold multiple data splits from the benchmark:\n",
    "\n",
    "- `ds_idx=0`: training set\n",
    "- `ds_idx=1`: validation set\n",
    "- `ds_idx=2` and above: test sets (if the benchmark provides them)\n",
    "\n",
    "Use `validate()` to compute the loss and metrics on any split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = lrn.validate(ds_idx=1)\n",
    "print(f\"Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5ce7b",
   "metadata": {},
   "source": [
    "## Getting Predictions\n",
    "\n",
    "`get_preds` returns a tuple of `(predictions, targets)` as tensors. This is\n",
    "useful for custom analysis, plotting, or computing metrics that aren't built\n",
    "into tsfast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccab03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = lrn.get_preds(ds_idx=1)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Targets shape: {targs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d13a6",
   "metadata": {},
   "source": [
    "## Training on a Different Dataset\n",
    "\n",
    "The same workflow applies to any benchmark dataset. Here we train on the\n",
    "Wiener-Hammerstein benchmark, which models a different nonlinear dynamic system.\n",
    "The only change is the DataLoader factory function -- the model architecture\n",
    "and training loop are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_wh = create_dls_wh()\n",
    "lrn_wh = RNNLearner(dls_wh, rnn_type='lstm', n_skip=50, hidden_size=40, metrics=[fun_rmse])\n",
    "lrn_wh.fit_flat_cos(n_epoch=10, lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_wh.show_results(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c59983",
   "metadata": {},
   "source": [
    "## Using Your Model: InferenceWrapper\n",
    "\n",
    "After training, you often want to run inference with numpy arrays -- for example,\n",
    "in a deployment pipeline or when integrating with scipy/control toolboxes.\n",
    "\n",
    "`InferenceWrapper` handles the full pipeline automatically:\n",
    "\n",
    "1. Converts numpy input to a PyTorch tensor\n",
    "2. Applies the same input normalization used during training\n",
    "3. Runs the model forward pass\n",
    "4. Converts the output back to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c096c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = InferenceWrapper(lrn)\n",
    "\n",
    "xb, yb = dls.valid.one_batch()\n",
    "np_input = xb.cpu().numpy()\n",
    "\n",
    "y_pred = wrapper.inference(np_input)\n",
    "print(f\"Input shape:  {np_input.shape}\")\n",
    "print(f\"Output shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012d419",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Simulation models predict output from input alone** (no output feedback).\n",
    "  The model must learn the full system dynamics from the excitation signal u(t).\n",
    "- **`n_skip` handles the RNN warmup transient** by excluding early timesteps from\n",
    "  the loss, so the model isn't penalized while its hidden state initializes.\n",
    "- **`ds_idx` selects which data split to evaluate**: 0 = train, 1 = valid,\n",
    "  2+ = test sets from the benchmark.\n",
    "- **`InferenceWrapper` provides numpy-in / numpy-out inference** with automatic\n",
    "  normalization, making it easy to use trained models outside of the training loop."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,scripts//py:percent"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
