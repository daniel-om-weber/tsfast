{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ba96a6",
   "metadata": {},
   "source": [
    "# Example 01: Understanding the Data Pipeline\n",
    "\n",
    "In Example 00, `create_dls_silverbox` handled everything behind the scenes:\n",
    "downloading data, creating sliding windows, splitting into train/validation\n",
    "sets, and normalizing inputs. This example reveals what is actually happening\n",
    "under the hood. You will learn how to use the general-purpose `create_dls`\n",
    "function directly, inspect the benchmark specification, and understand how\n",
    "TSFast normalizes your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485818e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- [Example 00: Your First Model](00_your_first_model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff1ef7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import identibench as idb\n",
    "\n",
    "from tsfast.datasets import create_dls\n",
    "from tsfast.datasets.benchmark import create_dls_silverbox\n",
    "from tsfast.models.rnn import RNNLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94daa935",
   "metadata": {},
   "source": [
    "## The Convenience Wrapper\n",
    "\n",
    "In Example 00, we loaded data with a single call to `create_dls_silverbox()`.\n",
    "This is a convenience wrapper that pre-fills all the benchmark-specific\n",
    "parameters (column names, dataset path, download URL) from the IdentiBench\n",
    "benchmark specification. Let's create the same DataLoaders again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8479ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_convenience = create_dls_silverbox(bs=16, win_sz=500, stp_sz=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b527f",
   "metadata": {},
   "source": [
    "## Inspecting the Benchmark Specification\n",
    "\n",
    "Every IdentiBench benchmark has a specification object that defines the input\n",
    "and output column names, the dataset download path, and other metadata. Let's\n",
    "look at the Silverbox specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6778ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = idb.BenchmarkSilverbox_Simulation\n",
    "print(f\"Input columns:  {spec.u_cols}\")\n",
    "print(f\"Output columns: {spec.y_cols}\")\n",
    "print(f\"Dataset path:   {spec.dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b996378a",
   "metadata": {},
   "source": [
    "## Building the DataLoaders Explicitly\n",
    "\n",
    "Now let's call `create_dls` directly, passing the same parameters that the\n",
    "convenience wrapper fills in for us. This gives you full control over every\n",
    "aspect of the data pipeline.\n",
    "\n",
    "Parameters explained:\n",
    "\n",
    "- **`u`** -- list of input signal column names in the HDF5 files. These are\n",
    "  the signals that drive the system (e.g., voltage applied to a circuit).\n",
    "- **`y`** -- list of output signal column names. These are the signals the\n",
    "  model learns to predict (e.g., the circuit's response).\n",
    "- **`dataset`** -- path to the dataset directory, which must contain `train/`,\n",
    "  `valid/`, and optionally `test/` subdirectories with HDF5 files.\n",
    "- **`win_sz`** -- window size: how many consecutive time steps make up one\n",
    "  training sample.\n",
    "- **`stp_sz`** -- step size: the stride between consecutive windows. A smaller\n",
    "  step size creates more overlapping windows and more training samples.\n",
    "- **`bs`** -- batch size: number of windows per training step.\n",
    "- **`n_batches_train`** -- fixed number of training batches per epoch. This\n",
    "  ensures consistent training time regardless of the total number of windows\n",
    "  in the dataset. Windows are sampled randomly each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_explicit = create_dls(\n",
    "    u=spec.u_cols,\n",
    "    y=spec.y_cols,\n",
    "    dataset=spec.dataset_path,\n",
    "    win_sz=500,\n",
    "    stp_sz=10,\n",
    "    bs=16,\n",
    "    n_batches_train=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b9da6",
   "metadata": {},
   "source": [
    "## Inspecting the Data\n",
    "\n",
    "`show_batch` visualizes random windows from the training set. The bottom\n",
    "subplot shows the input signal(s), and the upper subplot(s) show the output\n",
    "signal(s) that the model will learn to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c690b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_explicit.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf3d72",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "By default, TSFast normalizes **input signals only** using z-score\n",
    "normalization (subtract the mean, divide by the standard deviation). Output\n",
    "signals remain in their **original physical units**, which means model\n",
    "predictions are directly interpretable without any inverse transformation.\n",
    "\n",
    "The normalization statistics computed from the training set are stored in\n",
    "`dls.norm_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input normalization:\")\n",
    "print(f\"  Mean: {dls_explicit.norm_stats.u.mean}\")\n",
    "print(f\"  Std:  {dls_explicit.norm_stats.u.std}\")\n",
    "print()\n",
    "print(\"Output normalization:\")\n",
    "print(f\"  Mean: {dls_explicit.norm_stats.y.mean}\")\n",
    "print(f\"  Std:  {dls_explicit.norm_stats.y.std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412cc1c",
   "metadata": {},
   "source": [
    "## Training with the Explicit Pipeline\n",
    "\n",
    "Let's train the same LSTM model from Example 00 using our explicitly-built\n",
    "DataLoaders. The result should be comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = RNNLearner(dls_explicit, rnn_type='lstm')\n",
    "lrn.fit_flat_cos(n_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn.show_results(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abee10",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **`create_dls_silverbox`** is a convenience wrapper around `create_dls` with\n",
    "  pre-filled benchmark parameters (column names, dataset path, download\n",
    "  function).\n",
    "- **`create_dls`** is the general-purpose factory: it loads HDF5 files,\n",
    "  extracts sliding windows with configurable size (`win_sz`) and stride\n",
    "  (`stp_sz`), and splits the data by directory structure\n",
    "  (`train/`/`valid/`/`test/`).\n",
    "- **Inputs are normalized** (z-score), while **outputs stay in physical\n",
    "  units** so that predictions are directly interpretable.\n",
    "- **`dls.norm_stats`** stores the computed normalization statistics, accessible\n",
    "  as `.u` (inputs) and `.y` (outputs).\n",
    "- **`n_batches_train`** fixes the number of training batches per epoch,\n",
    "  decoupling training time from dataset size."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,scripts//py:percent"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
