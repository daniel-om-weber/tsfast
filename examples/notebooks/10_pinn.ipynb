{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774b8069",
   "metadata": {},
   "source": [
    "# Example 10: Physics-Informed Neural Networks (PINN)\n",
    "\n",
    "This example demonstrates how to train physics-informed RNNs for system\n",
    "identification. Two approaches are shown:\n",
    "\n",
    "1. **Basic RNN with collocation points** -- trained purely on physics\n",
    "   constraints, with no measured data fitting at all. The model learns to\n",
    "   satisfy the governing ODE on randomly generated excitation signals.\n",
    "2. **PIRNN (Physics-Informed RNN)** -- combines data fitting with physics\n",
    "   constraints and supports variable initial conditions via a StateEncoder.\n",
    "\n",
    "Both approaches embed the system's governing equations directly into the\n",
    "training loss, so the model is guided by physical laws rather than relying\n",
    "solely on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62942b",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- [Example 00: Your First Model](00_your_first_model.ipynb)\n",
    "- [Example 01: Understanding the Data Pipeline](01_data_pipeline.ipynb)\n",
    "- [Example 02: Simulation](02_simulation.ipynb)\n",
    "- [Example 03: Prediction -- Using Output Feedback](03_prediction.ipynb)\n",
    "- [Example 04: Benchmark RNN](04_benchmark_rnn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7400b7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tsfast.datasets.core import create_dls\n",
    "from tsfast.models.rnn import RNNLearner\n",
    "from tsfast.pinn.core import (\n",
    "    CollocationPointsCB,\n",
    "    PhysicsLossCallback,\n",
    "    generate_excitation_signals,\n",
    "    diff1_forward,\n",
    ")\n",
    "from tsfast.pinn.pirnn import PIRNNLearner\n",
    "from tsfast.learner.losses import fun_rmse, zero_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fe7cf",
   "metadata": {},
   "source": [
    "## The Spring-Damper System\n",
    "\n",
    "We model a mass-spring-damper system governed by the second-order ODE:\n",
    "\n",
    "```\n",
    "m * a + c * v + k * x = u\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "- **m** = mass\n",
    "- **c** = damping coefficient\n",
    "- **k** = spring constant\n",
    "- **x** = position, **v** = velocity, **a** = acceleration\n",
    "- **u** = external force (the input signal)\n",
    "\n",
    "The system has **1 input** (force u) and **2 outputs** (position x,\n",
    "velocity v). Our goal is to train a neural network that respects this\n",
    "physical law."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc843bc",
   "metadata": {},
   "source": [
    "## Physical Parameters and Physics Loss\n",
    "\n",
    "The physics loss function encodes the governing ODE as a training\n",
    "objective. It receives the model's input `u`, predictions `y_pred`, and\n",
    "(optionally) reference data `y_ref`, and returns a dictionary of loss\n",
    "components:\n",
    "\n",
    "- **`physics`**: residual of the ODE -- should be zero if the model\n",
    "  perfectly satisfies `ma + cv + kx = u`\n",
    "- **`derivative`**: consistency between velocity v and the numerical\n",
    "  derivative of position dx/dt\n",
    "- **`initial`**: penalizes deviation from measured initial conditions\n",
    "  (only when reference data `y_ref` is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cf883",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASS = 1.0\n",
    "SPRING_CONSTANT = 1.0\n",
    "DAMPING_COEFFICIENT = 0.1\n",
    "DT = 0.01\n",
    "\n",
    "\n",
    "def spring_damper_physics(u, y_pred, y_ref):\n",
    "    \"\"\"Physics loss for the spring-damper ODE: ma + cv + kx = u.\"\"\"\n",
    "    x, v = y_pred[:, :, 0], y_pred[:, :, 1]\n",
    "    u_force = u[:, :, 0]\n",
    "\n",
    "    a = diff1_forward(v, DT)\n",
    "    dx_dt = diff1_forward(x, DT)\n",
    "\n",
    "    loss = {\n",
    "        'physics': ((MASS * a + DAMPING_COEFFICIENT * v + SPRING_CONSTANT * x - u_force) ** 2).mean(),\n",
    "        'derivative': ((v - dx_dt) ** 2).mean(),\n",
    "    }\n",
    "\n",
    "    if y_ref is not None:\n",
    "        init_sz = 10\n",
    "        loss['initial'] = ((x[:, :init_sz] - y_ref[:, :init_sz, 0]) ** 2).mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed503c",
   "metadata": {},
   "source": [
    "## Load the PINN Dataset\n",
    "\n",
    "This example uses a locally bundled dataset in `test_data/pinn/`\n",
    "(no download needed). The HDF5 files contain three datasets: `u` (force),\n",
    "`x` (position), and `v` (velocity).\n",
    "\n",
    "We use a robust path resolution that works whether the code runs as a\n",
    "notebook (from `examples/notebooks/`) or as a script (from\n",
    "`examples/scripts/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _root = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    _root = Path(\".\").resolve().parent\n",
    "\n",
    "path = _root / \"test_data\" / \"pinn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df4bce9",
   "metadata": {},
   "source": [
    "Key parameters:\n",
    "\n",
    "- **`u=['u'], y=['x', 'v']`** -- column names matching the HDF5 dataset\n",
    "  keys\n",
    "- **`win_sz=100`** -- short windows because the PINN dataset has short\n",
    "  trajectories (500 samples at 100 Hz = 5 seconds)\n",
    "- **`stp_sz=1, valid_stp_sz=1`** -- step size of 1 gives maximum overlap\n",
    "  between windows for more training data\n",
    "- **`n_batches_train=300`** -- fixed number of training batches per epoch,\n",
    "  important for PINN training where we want many gradient steps per epoch\n",
    "- **`.cpu()`** -- PINN training is lightweight, CPU is sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls(\n",
    "    u=['u'], y=['x', 'v'],\n",
    "    dataset=path,\n",
    "    win_sz=100, stp_sz=1, valid_stp_sz=1,\n",
    "    bs=32, n_batches_train=300,\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b7ace",
   "metadata": {},
   "source": [
    "## Approach 1: Basic RNN with Collocation Points\n",
    "\n",
    "This trains a standard RNN using **only** physics constraints -- no data\n",
    "fitting at all. The model learns to satisfy the ODE on randomly generated\n",
    "excitation signals (collocation points). This is useful as a physics\n",
    "surrogate model: it can simulate the spring-damper system for any input\n",
    "signal without ever having seen measured data.\n",
    "\n",
    "Key design choices:\n",
    "\n",
    "- **`zero_loss`** as the data loss: returns 0 for every batch. Physics is\n",
    "  the **only** training signal. The model does not try to fit any specific\n",
    "  trajectory.\n",
    "- **`CollocationPointsCB`** generates random excitation signals each batch\n",
    "  and computes the physics loss on the model's response to those signals.\n",
    "- **`generate_excitation_signals`** creates random input signals (sines,\n",
    "  steps, chirps, etc.). `amplitude_range` and `frequency_range` control\n",
    "  the signal characteristics.\n",
    "- **`num_workers=1`** -- number of parallel workers for collocation point\n",
    "  generation. Must be at least 1 (0 is not supported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner(\n",
    "    dls, rnn_type='lstm', num_layers=1, hidden_size=10,\n",
    "    loss_func=zero_loss, metrics=[fun_rmse],\n",
    ")\n",
    "\n",
    "learn.add_cb(CollocationPointsCB(\n",
    "    generate_pinn_input=lambda bs, sl, dev: generate_excitation_signals(\n",
    "        bs, sl, n_inputs=1, dt=DT, device=dev,\n",
    "        amplitude_range=(0.5, 2.0), frequency_range=(0.1, 3.0),\n",
    "    ),\n",
    "    physics_loss_func=spring_damper_physics,\n",
    "    weight=1.0,\n",
    "    num_workers=1,\n",
    "))\n",
    "\n",
    "learn.fit_flat_cos(10, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3895ef8",
   "metadata": {},
   "source": [
    "## Approach 1: Results\n",
    "\n",
    "Since the model was trained purely on physics constraints, it has learned\n",
    "to produce outputs that satisfy the ODE -- even though it never saw the\n",
    "actual measured trajectories during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=3, ds_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87b043",
   "metadata": {},
   "source": [
    "## Approach 2: PIRNN with Data + Physics\n",
    "\n",
    "PIRNN (Physics-Informed RNN) combines data fitting with physics\n",
    "constraints. It uses a dual-encoder architecture:\n",
    "\n",
    "- A **SequenceEncoder** (diagnosis RNN) that processes an initialization\n",
    "  window of measured data to estimate the system's hidden state\n",
    "- A **StateEncoder** (MLP) that maps a single physical state vector\n",
    "  directly to the RNN hidden state, enabling variable initial conditions\n",
    "  at inference without needing a full initialization sequence\n",
    "\n",
    "Two callbacks enforce physics:\n",
    "\n",
    "- **`PhysicsLossCallback`**: computes the physics loss on actual training\n",
    "  data batches\n",
    "- **`CollocationPointsCB`**: computes the physics loss on randomly\n",
    "  generated input signals for better generalization\n",
    "\n",
    "Key parameters:\n",
    "\n",
    "- **`init_sz=10`** -- number of timesteps used for initialization\n",
    "  (shorter than FranSys since we have a StateEncoder as backup)\n",
    "- **`attach_output=True`** -- enables prediction mode, where the model\n",
    "  receives past outputs as additional input\n",
    "- **`state_encoder_hidden=32`** -- hidden dimension of the StateEncoder\n",
    "  MLP\n",
    "- **`loss_weights`** -- relative importance of each physics loss\n",
    "  component. `initial` is weighted 10x higher to anchor predictions to\n",
    "  measured initial conditions.\n",
    "- **`init_mode='state_encoder'`** -- tells the collocation callback to\n",
    "  initialize the model via the StateEncoder with random physical states\n",
    "- **`output_ranges`** -- physical ranges for random state generation,\n",
    "  one (min, max) tuple per output channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb302925",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = PIRNNLearner(\n",
    "    dls, init_sz=10, attach_output=True,\n",
    "    rnn_type='gru', rnn_layer=1, hidden_size=20,\n",
    "    state_encoder_hidden=32,\n",
    "    loss_func=zero_loss, metrics=[fun_rmse],\n",
    ")\n",
    "\n",
    "# Physics on training data\n",
    "learn.add_cb(PhysicsLossCallback(\n",
    "    physics_loss_func=spring_damper_physics,\n",
    "    weight=1.0,\n",
    "    loss_weights={'physics': 1.0, 'derivative': 1.0, 'initial': 10.0},\n",
    "    n_inputs=1,\n",
    "))\n",
    "\n",
    "# Physics on collocation points with StateEncoder initialization\n",
    "learn.add_cb(CollocationPointsCB(\n",
    "    generate_pinn_input=lambda bs, sl, dev: generate_excitation_signals(\n",
    "        bs, sl, n_inputs=1, dt=DT, device=dev,\n",
    "        amplitude_range=(0.5, 2.0), frequency_range=(0.1, 3.0),\n",
    "    ),\n",
    "    physics_loss_func=spring_damper_physics,\n",
    "    weight=0.5,\n",
    "    init_mode='state_encoder',\n",
    "    output_ranges=[(-1.0, 1.0), (-2.0, 2.0)],\n",
    "    num_workers=1,\n",
    "))\n",
    "\n",
    "learn.fit_flat_cos(50, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d4f0e",
   "metadata": {},
   "source": [
    "## Approach 2: Results\n",
    "\n",
    "The PIRNN model benefits from both data fitting and physics constraints.\n",
    "The StateEncoder allows it to handle variable initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=3, ds_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa040c",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **PINNs embed physical laws directly into the training process** via\n",
    "  custom loss functions that penalize ODE residuals.\n",
    "- **Approach 1 (collocation only)** creates a physics surrogate model\n",
    "  with no measured data -- useful when the governing equations are known\n",
    "  but data is unavailable.\n",
    "- **Approach 2 (PIRNN)** combines data fitting with physics constraints\n",
    "  for better accuracy and generalization.\n",
    "- **`zero_loss`** is used when physics is the only training signal -- it\n",
    "  returns 0 so the physics callbacks provide 100% of the gradient.\n",
    "- **`PhysicsLossCallback`** enforces physics on real training data;\n",
    "  **`CollocationPointsCB`** enforces physics on randomly generated\n",
    "  excitation signals for broader coverage.\n",
    "- **`StateEncoder`** maps a physical state vector to an RNN hidden state,\n",
    "  enabling variable initial conditions without a full initialization\n",
    "  sequence.\n",
    "- PINNs are especially useful when **data is scarce but the governing\n",
    "  equations are known**."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,scripts//py:percent"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
