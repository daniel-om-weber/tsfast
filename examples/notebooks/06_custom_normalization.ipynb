{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81f7bb6",
   "metadata": {},
   "source": [
    "# Example 06: Custom Normalization\n",
    "\n",
    "Neural networks train faster when inputs are properly scaled. TSFast\n",
    "normalizes inputs by default using z-score normalization. This example shows\n",
    "all built-in scalers, compares their effects on training, and demonstrates\n",
    "how to create a custom scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f1aa6",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- [Example 00: Your First Model](00_your_first_model.ipynb)\n",
    "- [Example 01: Understanding the Data Pipeline](01_data_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502eedd5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tsfast.datasets.benchmark import create_dls_silverbox\n",
    "from tsfast.models.rnn import RNNLearner\n",
    "from tsfast.models.layers import Scaler, StandardScaler1D, MinMaxScaler1D, MaxAbsScaler1D\n",
    "from tsfast.learner.losses import fun_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95f204",
   "metadata": {},
   "source": [
    "## Why Normalization Matters\n",
    "\n",
    "Neural networks learn best when input features are on similar scales. Without\n",
    "normalization, features with large magnitudes dominate gradient updates,\n",
    "causing slow or unstable training. TSFast automatically normalizes input\n",
    "signals by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24545d1b",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls_silverbox(bs=16, win_sz=500, stp_sz=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab5797",
   "metadata": {},
   "source": [
    "## Built-in Scalers\n",
    "\n",
    "TSFast provides three built-in scalers:\n",
    "\n",
    "- **`StandardScaler1D`** (default): z-score normalization.\n",
    "  `x_norm = (x - mean) / std`\n",
    "- **`MinMaxScaler1D`**: scales to [0, 1].\n",
    "  `x_norm = (x - min) / (max - min)`\n",
    "- **`MaxAbsScaler1D`**: scales to [-1, 1].\n",
    "  `x_norm = x / max(|min|, |max|)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d22dfa",
   "metadata": {},
   "source": [
    "## Training with Different Scalers\n",
    "\n",
    "Train with each scaler for a fair comparison. All models use the same\n",
    "architecture and training schedule so the only difference is the scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c070aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_std = RNNLearner(dls, rnn_type='lstm', metrics=[fun_rmse])\n",
    "lrn_std.fit_flat_cos(n_epoch=5, lr=3e-3)\n",
    "print(f\"StandardScaler1D: {lrn_std.validate()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_mm = RNNLearner(dls, rnn_type='lstm', input_norm=MinMaxScaler1D, metrics=[fun_rmse])\n",
    "lrn_mm.fit_flat_cos(n_epoch=5, lr=3e-3)\n",
    "print(f\"MinMaxScaler1D:   {lrn_mm.validate()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af492a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_ma = RNNLearner(dls, rnn_type='lstm', input_norm=MaxAbsScaler1D, metrics=[fun_rmse])\n",
    "lrn_ma.fit_flat_cos(n_epoch=5, lr=3e-3)\n",
    "print(f\"MaxAbsScaler1D:   {lrn_ma.validate()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ef361",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_none = RNNLearner(dls, rnn_type='lstm', input_norm=None, metrics=[fun_rmse])\n",
    "lrn_none.fit_flat_cos(n_epoch=5, lr=3e-3)\n",
    "print(f\"No normalization: {lrn_none.validate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5586f",
   "metadata": {},
   "source": [
    "## Output Normalization\n",
    "\n",
    "By default, only inputs are normalized and outputs stay in physical units.\n",
    "For multi-output systems where outputs have very different scales, you can\n",
    "also normalize outputs. Predictions are automatically denormalized back to\n",
    "physical units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac7eed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "lrn_out = RNNLearner(dls, rnn_type='lstm', output_norm=StandardScaler1D, metrics=[fun_rmse])\n",
    "lrn_out.fit_flat_cos(n_epoch=5, lr=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e263f",
   "metadata": {},
   "source": [
    "## Creating a Custom Scaler\n",
    "\n",
    "To create a custom scaler, subclass `Scaler` and implement three methods:\n",
    "`normalize`, `denormalize`, and the `from_stats` classmethod. Here is an\n",
    "example that clips values to a fixed range and then scales to [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipScaler(Scaler):\n",
    "    \"\"\"Clips values to [-clip_val, clip_val] then scales to [-1, 1].\"\"\"\n",
    "\n",
    "    def __init__(self, clip_val: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.register_buffer('clip_val', clip_val)\n",
    "\n",
    "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.clamp(x, -self.clip_val, self.clip_val) / self.clip_val\n",
    "\n",
    "    def denormalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.clip_val\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, stats):\n",
    "        clip_val = torch.max(torch.abs(torch.tensor(stats.min)),\n",
    "                             torch.abs(torch.tensor(stats.max))).float()\n",
    "        return cls(clip_val.unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04be8cf",
   "metadata": {},
   "source": [
    "`from_stats` receives a `NormPair` object containing the dataset statistics\n",
    "(`mean`, `std`, `min`, `max` as 1-D arrays) and must return a configured\n",
    "scaler instance. `register_buffer` ensures the parameters move with the\n",
    "model to GPU/CPU automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7c53c",
   "metadata": {},
   "source": [
    "Train with the custom scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_custom = RNNLearner(dls, rnn_type='lstm', input_norm=ClipScaler, metrics=[fun_rmse])\n",
    "lrn_custom.fit_flat_cos(n_epoch=5, lr=3e-3)\n",
    "print(f\"ClipScaler:       {lrn_custom.validate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21112bd",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491afe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_custom.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57d904",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **`StandardScaler1D`** (z-score) is the default and works well for most\n",
    "  problems.\n",
    "- **`MinMaxScaler1D`** and **`MaxAbsScaler1D`** are alternatives for bounded\n",
    "  signals.\n",
    "- **`input_norm=None`** disables normalization (useful for pre-normalized\n",
    "  data).\n",
    "- **`output_norm=StandardScaler1D`** normalizes outputs for multi-scale\n",
    "  training. Predictions are automatically denormalized.\n",
    "- Custom scalers subclass `Scaler` with `normalize`, `denormalize`, and\n",
    "  `from_stats`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,scripts//py:percent"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
